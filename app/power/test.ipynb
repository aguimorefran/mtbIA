{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import RNN, LSTMCell\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "RAW_DATA_PATH = \"../data/activity_data_raw.csv\"\n",
    "PLANNED_WORKOUTS_PATH = \"../data/planned_workouts.csv\"\n",
    "TARGET_FEATURES = [\"power_5s_avg\"]\n",
    "FEATURES = [\"grade\", \"ascent_meters\", \"distance_meters\", \"atl_start\", \"ctl_start\", \"watt_kg\", \"temperature\", \"distance_diff\", \"grade_5s_avg\", \"grade_diff\"]\n",
    "ALL_FEATURES = TARGET_FEATURES + FEATURES\n",
    "MODEL_PATH = \"../models/LSTM_power.keras\"\n",
    "METRICS_PATH = \"../data/model_metrics_power.csv\"\n",
    "\n",
    "def load_activity_data(csv_path):\n",
    "    logger.info(f\"Loading data from {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    logger.info(\"Data loaded successfully\")\n",
    "    return df\n",
    "\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def preprocess_data(df, drop_activities_with_workout=False):\n",
    "    logger.info(\"Starting data preprocessing\")\n",
    "    df = df.sort_values(by=[\"activity_id\", \"timestamp\"])\n",
    "    df[\"altitude_diff\"] = df[\"altitude\"].diff()\n",
    "    df[\"distance_diff\"] = df[\"distance\"].diff()\n",
    "    df[\"ascent_meters\"] = df[\"altitude_diff\"].apply(lambda x: x if x > 0 else 0).cumsum()\n",
    "    df[\"grade_diff\"] = df[\"grade\"].diff().fillna(0)\n",
    "    df[\"seconds_from_start\"] = (df[\"timestamp\"] - df[\"timestamp\"].iloc[0]).dt.total_seconds()\n",
    "    df.rename(columns={\"distance\": \"distance_meters\"}, inplace=True)\n",
    "    \n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    df[\"power_5s_avg\"] = df[\"power\"].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "    planned_workouts = pd.read_csv(PLANNED_WORKOUTS_PATH)\n",
    "\n",
    "    if drop_activities_with_workout:\n",
    "        intersecting_activities = planned_workouts[\"paired_activity_id\"].unique()\n",
    "        logger.info(f\"Dropping {len(intersecting_activities)} activities with planned workouts\")\n",
    "        df = df[~df[\"activity_id\"].isin(intersecting_activities)]\n",
    "        logger.info(f\"Remaining activities: {df['activity_id'].nunique()}\")\n",
    "\n",
    "    rows_na = df.isna().sum().sum()\n",
    "    df.dropna(inplace=True)\n",
    "    logger.info(f\"Dropped {rows_na} rows with NaN values\")\n",
    "    if df[ALL_FEATURES].isnull().values.any() or np.isinf(df[ALL_FEATURES]).values.any():\n",
    "        logger.error(\"NaN or infinite values found in the data\")\n",
    "        raise ValueError(\"NaN or infinite values found in the data\")\n",
    "\n",
    "    logger.info(\"Data preprocessing completed\")\n",
    "    return df\n",
    "\n",
    "def split_by_activities(df, test_size=0.2, val_size=0.1):\n",
    "    activity_ids = df['activity_id'].unique()\n",
    "    train_ids, test_ids = train_test_split(activity_ids, test_size=test_size, random_state=42)\n",
    "    train_ids, val_ids = train_test_split(train_ids, test_size=val_size / (1 - test_size), random_state=42)\n",
    "    \n",
    "    train_df = df[df['activity_id'].isin(train_ids)]\n",
    "    val_df = df[df['activity_id'].isin(val_ids)]\n",
    "    test_df = df[df['activity_id'].isin(test_ids)]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def scale_data(train, val, test):\n",
    "    train_scaled = train.copy()\n",
    "    val_scaled = val.copy()\n",
    "    test_scaled = test.copy()\n",
    "    \n",
    "    features = FEATURES + TARGET_FEATURES\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train[features])\n",
    "    \n",
    "    train_scaled[features] = scaler.transform(train[features])\n",
    "    val_scaled[features] = scaler.transform(val[features])\n",
    "    test_scaled[features] = scaler.transform(test[features])\n",
    "    \n",
    "    return train_scaled, val_scaled, test_scaled\n",
    "\n",
    "def augment_data(seq, aug_methods):\n",
    "    method = np.random.choice(aug_methods)\n",
    "    if method == 'noise':\n",
    "        noise = np.random.normal(0, 0.01, seq.shape)\n",
    "        return seq + noise\n",
    "    elif method == 'scaling':\n",
    "        factor = np.random.uniform(0.9, 1.1)\n",
    "        return seq * factor\n",
    "    elif method == 'shifting':\n",
    "        shift = np.random.randint(-3, 3)\n",
    "        return np.roll(seq, shift, axis=0)\n",
    "    elif method == 'time_warping':\n",
    "        time_steps = np.arange(seq.shape[0])\n",
    "        warp = np.interp(time_steps, time_steps, seq)\n",
    "        return warp\n",
    "    return seq\n",
    "\n",
    "def create_sequences(data, sequence_length, target_columns, augmentation=False):\n",
    "    num_records = len(data)\n",
    "    num_features = len(FEATURES)\n",
    "    num_targets = len(target_columns)\n",
    "\n",
    "    sequences = np.zeros((num_records - sequence_length, sequence_length, num_features), dtype=np.float32)\n",
    "    targets = np.zeros((num_records - sequence_length, num_targets), dtype=np.float32)\n",
    "\n",
    "    feature_data = data[FEATURES].values\n",
    "    target_data = data[target_columns].values\n",
    "\n",
    "    for i in range(num_records - sequence_length):\n",
    "        seq = feature_data[i:i + sequence_length]\n",
    "        if augmentation:\n",
    "            seq = augment_data(seq, ['noise', 'scaling', 'shifting'])\n",
    "        sequences[i] = seq\n",
    "        targets[i] = target_data[i + sequence_length]\n",
    "\n",
    "    return sequences, targets\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def build_model(\n",
    "        learning_rate=0.001,\n",
    "        cnn_filters=[],\n",
    "        dense_units=[],\n",
    "        lstm_units=[1],\n",
    "        sequence_length=60,\n",
    "        dropout_rate_dense=0, \n",
    "        dropout_rate_lstm=0,\n",
    "        dropout_rate_cnn=0,\n",
    "        add_batch_norm=False,\n",
    "        l2_reg=0.01,\n",
    "):\n",
    "    model = Sequential()\n",
    "\n",
    "    # CNN LAYERS\n",
    "    if cnn_filters:\n",
    "        for i, num_filters in enumerate(cnn_filters):\n",
    "            if i == 0:\n",
    "                model.add(tf.keras.layers.Conv1D(filters=num_filters, kernel_size=3, activation='relu', input_shape=(sequence_length, len(FEATURES))))\n",
    "            else:\n",
    "                model.add(tf.keras.layers.Conv1D(filters=num_filters, kernel_size=3, activation='relu'))\n",
    "            model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "            model.add(Dropout(dropout_rate_cnn))\n",
    "        if add_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "    \n",
    "    # LSTM LAYERS\n",
    "    for i, num_units in enumerate(lstm_units):\n",
    "        return_seq = True if i < len(lstm_units) - 1 else False\n",
    "        model.add(RNN(LSTMCell(num_units, activation='tanh', kernel_regularizer=l2(l2_reg)), return_sequences=return_seq))\n",
    "        if add_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate_lstm))\n",
    "\n",
    "    # DENSE LAYERS\n",
    "    if dense_units:\n",
    "        for i, num_units in enumerate(dense_units):\n",
    "            model.add(Dense(num_units, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "            if add_batch_norm:\n",
    "                model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout_rate_dense))\n",
    "\n",
    "    model.add(Dense(len(TARGET_FEATURES)))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "    \n",
    "    logger.info(\"LSTM model built and compiled\")\n",
    "    return model\n",
    "\n",
    "def get_model_metrics(model, sequences, targets):\n",
    "    logger.info(\"Getting model metrics\")\n",
    "    predictions = model.predict(sequences)\n",
    "    metrics = {}\n",
    "    for i, target in enumerate(TARGET_FEATURES):\n",
    "        metric = tf.keras.metrics.mean_squared_error(targets[:, i], predictions[:, i]).numpy()\n",
    "        metrics[target] = metric\n",
    "    logger.info(f\"Model metrics: {metrics}\")\n",
    "    return metrics\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def predict_first_n_points(df, model, sequence_length, n_points=100, seed=42):\n",
    "    activity_id = df['activity_id'].sample(1, random_state=seed).values[0]\n",
    "    activity_data = df[df['activity_id'] == activity_id]\n",
    "    \n",
    "    if len(activity_data) < sequence_length + n_points:\n",
    "        print(f\"La actividad {activity_id} no tiene suficientes puntos para la predicciÃ³n. Se requieren al menos {sequence_length + n_points} puntos, pero la actividad tiene {len(activity_data)} puntos.\")\n",
    "        return\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(activity_data[FEATURES])\n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(n_points):\n",
    "        seq = scaled_features[i:i + sequence_length]\n",
    "        sequences.append(seq)\n",
    "    \n",
    "    sequences = np.array(sequences)\n",
    "    predictions = model.predict(sequences)\n",
    "    \n",
    "    power_scaler = StandardScaler()\n",
    "    power_scaler.fit(activity_data[TARGET_FEATURES])\n",
    "    predictions = power_scaler.inverse_transform(predictions)\n",
    "    \n",
    "    actual_power = activity_data[TARGET_FEATURES].iloc[sequence_length:sequence_length + n_points].values\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    ax1.set_xlabel('Timestep')\n",
    "    ax1.set_ylabel(TARGET_FEATURES[0])\n",
    "    ax1.plot(range(n_points), actual_power, label='Actual %s' % TARGET_FEATURES[0], color='tab:blue')\n",
    "    ax1.plot(range(n_points), predictions, label='Predicted Power', color='tab:red')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "    plt.title(f'Activity ID: {activity_id}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 01:00:03,773 - Loading data from ../data/activity_data_raw.csv\n",
      "2024-06-08 01:00:04,418 - Data loaded successfully\n",
      "2024-06-08 01:00:04,419 - Starting data preprocessing\n",
      "C:\\Users\\Fco\\AppData\\Local\\Temp\\ipykernel_23904\\4070497308.py:54: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Fco\\AppData\\Local\\Temp\\ipykernel_23904\\4070497308.py:55: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n",
      "2024-06-08 01:00:04,616 - Dropping 39 activities with planned workouts\n",
      "2024-06-08 01:00:04,630 - Remaining activities: 16\n",
      "2024-06-08 01:00:04,654 - Dropped 0 rows with NaN values\n",
      "2024-06-08 01:00:04,660 - Data preprocessing completed\n",
      "2024-06-08 01:00:05,900 - LSTM model built and compiled\n",
      "2024-06-08 01:00:06,231 - Training sequences shape: (57406, 30, 10)\n",
      "2024-06-08 01:00:06,232 - Training targets shape: (57406, 1)\n"
     ]
    }
   ],
   "source": [
    "LR_INIT = 0.001\n",
    "SEQ_LENGTH = 30\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 100\n",
    "augment_data_flag = True\n",
    "\n",
    "# LSTM\n",
    "LSTM_UNITS = [128, 64]\n",
    "DROPOUT_RATE_LSTM = 0.2\n",
    "\n",
    "# DENSE\n",
    "DENSE_UNITS = [32, 16]\n",
    "DROPOUT_RATE_DENSE = 0.2\n",
    "\n",
    "# CNN\n",
    "CNN_FILTERS = []\n",
    "DROPOUT_RATE_CNN = 0.2\n",
    "\n",
    "# Other\n",
    "ADD_BATCH_NORM = True\n",
    "PATIENCE = 10\n",
    "L2_REG = 0.02\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "df = load_activity_data(RAW_DATA_PATH)\n",
    "df = preprocess_data(df, drop_activities_with_workout=True)\n",
    "\n",
    "train_df, val_df, test_df = split_by_activities(df)\n",
    "\n",
    "train_scaled, val_scaled, test_scaled = scale_data(train_df, val_df, test_df)\n",
    "\n",
    "train_sequences, train_targets = create_sequences(train_scaled, SEQ_LENGTH, TARGET_FEATURES, augmentation=augment_data_flag)\n",
    "val_sequences, val_targets = create_sequences(val_scaled, SEQ_LENGTH, TARGET_FEATURES, augmentation=False)\n",
    "test_sequences, test_targets = create_sequences(test_scaled, SEQ_LENGTH, TARGET_FEATURES, augmentation=False)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "\n",
    "model = build_model(\n",
    "    add_batch_norm=ADD_BATCH_NORM,\n",
    "    learning_rate=LR_INIT,\n",
    "    lstm_units=LSTM_UNITS,\n",
    "    dense_units=DENSE_UNITS,\n",
    "    cnn_filters=CNN_FILTERS,\n",
    "    sequence_length=SEQ_LENGTH,\n",
    "    dropout_rate_lstm=DROPOUT_RATE_LSTM,\n",
    "    dropout_rate_dense=DROPOUT_RATE_DENSE,\n",
    "    dropout_rate_cnn=DROPOUT_RATE_CNN,\n",
    "    l2_reg=L2_REG\n",
    ")\n",
    "\n",
    "model.build(input_shape=(None, SEQ_LENGTH, len(FEATURES)))\n",
    "\n",
    "\n",
    "# Print the number of sequences and targets that will be used for training\n",
    "logger.info(f\"Training sequences shape: {train_sequences.shape}\")\n",
    "logger.info(f\"Training targets shape: {train_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-06-08 01:00:06,709] A new study created in RDB with name: example_study\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 128) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (32, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100, 100) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 64, 32) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 32, 16) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (32, 16) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains () which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (32, 64) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 128) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "2024-06-08 01:00:07,010 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.10174, saving model to checkpoint_trial_0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [128] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [128, 128] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [128, 64] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64, 32] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64, 64] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [32, 32] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [50, 50, 50] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [100, 100, 100] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [128, 64, 32] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64, 32, 16] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [32, 16] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [32, 64] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\optuna\\distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [64, 128] which is of type list.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.10174 to 0.87540, saving model to checkpoint_trial_0.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.87540 to 0.49779, saving model to checkpoint_trial_0.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49779\n",
      "\n",
      "Epoch 12: val_loss improved from 0.49779 to 0.47216, saving model to checkpoint_trial_0.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.47216\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.47216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:01:22,800] Trial 0 finished with value: 0.4721550941467285 and parameters: {'learning_rate': 0.008250259191241739, 'lstm_units': [100, 100, 100], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.4912801438488539, 'dropout_rate_dense': 0.22085029232914855, 'dropout_rate_cnn': 0.04177913064883143, 'l2_reg': 0.06914926684234356, 'cnn_filters': [128, 64]}. Best is trial 0 with value: 0.4721550941467285.\n",
      "2024-06-08 01:01:23,054 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 17.25173, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 17.25173 to 13.03787, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 13.03787 to 9.85042, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 9.85042 to 7.40653, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 7.40653 to 5.58241, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 5.58241 to 4.18295, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 4.18295 to 3.16072, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 3.16072 to 2.38376, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 2.38376 to 1.83579, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 1.83579 to 1.42073, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 1.42073 to 1.15072, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 1.15072 to 0.97555, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.97555 to 0.83928, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.83928 to 0.75410, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.75410 to 0.69189, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.69189 to 0.62866, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.62866 to 0.59521, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.59521 to 0.56630, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.56630 to 0.54395, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.54395 to 0.52348, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.52348 to 0.51242, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.51242 to 0.50242, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.50242 to 0.48610, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.48610\n",
      "\n",
      "Epoch 25: val_loss improved from 0.48610 to 0.47863, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.47863 to 0.47151, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.47151\n",
      "\n",
      "Epoch 28: val_loss improved from 0.47151 to 0.46543, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.46543 to 0.46079, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.46079 to 0.45920, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.45920 to 0.45773, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.45773 to 0.45238, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.45238 to 0.45232, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.45232 to 0.44756, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.44756\n",
      "\n",
      "Epoch 36: val_loss improved from 0.44756 to 0.44557, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.44557 to 0.44503, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.44503\n",
      "\n",
      "Epoch 39: val_loss improved from 0.44503 to 0.44316, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.44316 to 0.44308, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.44308 to 0.44086, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.44086\n",
      "\n",
      "Epoch 43: val_loss improved from 0.44086 to 0.43957, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 44: val_loss improved from 0.43957 to 0.43954, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.43954 to 0.43944, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 46: val_loss improved from 0.43944 to 0.43895, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.43895 to 0.43825, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.43825\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.43825\n",
      "\n",
      "Epoch 50: val_loss improved from 0.43825 to 0.43752, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.43752\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.43752\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.43752\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.43752\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.43752\n",
      "\n",
      "Epoch 56: val_loss improved from 0.43752 to 0.43667, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 57: val_loss improved from 0.43667 to 0.43661, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 58: val_loss improved from 0.43661 to 0.43623, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.43623\n",
      "\n",
      "Epoch 60: val_loss improved from 0.43623 to 0.43592, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.43592\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.43592\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.43592\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.43592\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.43592\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.43592\n",
      "\n",
      "Epoch 67: val_loss improved from 0.43592 to 0.43591, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 68: val_loss improved from 0.43591 to 0.43553, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 69: val_loss improved from 0.43553 to 0.43547, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.43547\n",
      "\n",
      "Epoch 71: val_loss improved from 0.43547 to 0.43539, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 72: val_loss improved from 0.43539 to 0.43520, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.43520\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.43520\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.43520\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.43520\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.43520\n",
      "\n",
      "Epoch 78: val_loss improved from 0.43520 to 0.43518, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 79: val_loss improved from 0.43518 to 0.43517, saving model to checkpoint_trial_1.h5\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.43517\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.43517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:04:58,153] Trial 1 finished with value: 0.4351724088191986 and parameters: {'learning_rate': 0.0003219801586419078, 'lstm_units': [32, 32], 'dense_units': [64, 64], 'dropout_rate_lstm': 0.35542739273518587, 'dropout_rate_dense': 0.481388045644432, 'dropout_rate_cnn': 0.11201489119295921, 'l2_reg': 0.09039928273413976, 'cnn_filters': [128, 64]}. Best is trial 1 with value: 0.4351724088191986.\n",
      "2024-06-08 01:04:58,399 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 19.96850, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 19.96850 to 16.68298, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 16.68298 to 13.95823, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 13.95823 to 11.64880, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 11.64880 to 9.68703, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 9.68703 to 8.08022, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 8.08022 to 6.75252, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 6.75252 to 5.63763, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 5.63763 to 4.71954, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 4.71954 to 3.95129, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 3.95129 to 3.36808, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 3.36808 to 2.91932, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 2.91932 to 2.56526, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 2.56526 to 2.28475, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 2.28475 to 2.06572, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 2.06572 to 1.88354, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 1.88354 to 1.73753, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 1.73753 to 1.60833, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 1.60833 to 1.50287, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 1.50287 to 1.41414, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 1.41414 to 1.33841, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 1.33841 to 1.27879, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 1.27879 to 1.21981, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 1.21981 to 1.17324, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 1.17324 to 1.12876, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 1.12876 to 1.09580, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 1.09580 to 1.06322, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 1.06322 to 1.03486, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 1.03486 to 1.01027, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 1.01027 to 0.98955, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.98955 to 0.97074, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.97074 to 0.95281, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.95281 to 0.93657, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.93657 to 0.92406, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.92406 to 0.91140, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.91140 to 0.90023, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.90023 to 0.88902, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.88902 to 0.88109, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.88109 to 0.87180, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.87180 to 0.86582, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.86582 to 0.85792, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 42: val_loss improved from 0.85792 to 0.85293, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 43: val_loss improved from 0.85293 to 0.84710, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 44: val_loss improved from 0.84710 to 0.84148, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.84148 to 0.83735, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 46: val_loss improved from 0.83735 to 0.83286, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.83286 to 0.82949, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 48: val_loss improved from 0.82949 to 0.82680, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 49: val_loss improved from 0.82680 to 0.82314, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 50: val_loss improved from 0.82314 to 0.81962, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 51: val_loss improved from 0.81962 to 0.81782, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 52: val_loss improved from 0.81782 to 0.81515, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 53: val_loss improved from 0.81515 to 0.81343, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 54: val_loss improved from 0.81343 to 0.81120, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 55: val_loss improved from 0.81120 to 0.80937, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 56: val_loss improved from 0.80937 to 0.80791, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 57: val_loss improved from 0.80791 to 0.80632, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 58: val_loss improved from 0.80632 to 0.80503, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 59: val_loss improved from 0.80503 to 0.80341, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 60: val_loss improved from 0.80341 to 0.80228, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 61: val_loss improved from 0.80228 to 0.80123, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 62: val_loss improved from 0.80123 to 0.80030, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 63: val_loss improved from 0.80030 to 0.79962, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 64: val_loss improved from 0.79962 to 0.79890, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 65: val_loss improved from 0.79890 to 0.79807, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 66: val_loss improved from 0.79807 to 0.79739, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 67: val_loss improved from 0.79739 to 0.79693, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 68: val_loss improved from 0.79693 to 0.79623, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 69: val_loss improved from 0.79623 to 0.79571, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 70: val_loss improved from 0.79571 to 0.79533, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 71: val_loss improved from 0.79533 to 0.79497, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 72: val_loss improved from 0.79497 to 0.79457, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 73: val_loss improved from 0.79457 to 0.79413, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 74: val_loss improved from 0.79413 to 0.79392, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 75: val_loss improved from 0.79392 to 0.79362, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 76: val_loss improved from 0.79362 to 0.79338, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 77: val_loss improved from 0.79338 to 0.79320, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 78: val_loss improved from 0.79320 to 0.79297, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 79: val_loss improved from 0.79297 to 0.79279, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 80: val_loss improved from 0.79279 to 0.79264, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 81: val_loss improved from 0.79264 to 0.79246, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 82: val_loss improved from 0.79246 to 0.79230, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 83: val_loss improved from 0.79230 to 0.79222, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 84: val_loss improved from 0.79222 to 0.79209, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 85: val_loss improved from 0.79209 to 0.79199, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 86: val_loss improved from 0.79199 to 0.79188, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 87: val_loss improved from 0.79188 to 0.79181, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 88: val_loss improved from 0.79181 to 0.79169, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 89: val_loss improved from 0.79169 to 0.79160, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 90: val_loss improved from 0.79160 to 0.79152, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 91: val_loss improved from 0.79152 to 0.79147, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 92: val_loss improved from 0.79147 to 0.79140, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 93: val_loss improved from 0.79140 to 0.79136, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 94: val_loss improved from 0.79136 to 0.79131, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 95: val_loss improved from 0.79131 to 0.79127, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 96: val_loss improved from 0.79127 to 0.79123, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 97: val_loss improved from 0.79123 to 0.79119, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 98: val_loss improved from 0.79119 to 0.79115, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 99: val_loss improved from 0.79115 to 0.79113, saving model to checkpoint_trial_2.h5\n",
      "\n",
      "Epoch 100: val_loss improved from 0.79113 to 0.79110, saving model to checkpoint_trial_2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:08:43,757] Trial 2 finished with value: 0.7910997271537781 and parameters: {'learning_rate': 0.00014468266007483678, 'lstm_units': [128, 64], 'dense_units': [128, 64], 'dropout_rate_lstm': 0.061138816134023555, 'dropout_rate_dense': 0.4259209576438441, 'dropout_rate_cnn': 0.3745160506114414, 'l2_reg': 0.0574940396959732, 'cnn_filters': [64, 32]}. Best is trial 1 with value: 0.4351724088191986.\n",
      "2024-06-08 01:08:44,054 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 21.59205, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 21.59205 to 18.30189, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 18.30189 to 15.51567, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 15.51567 to 13.13441, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 13.13441 to 11.10867, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 11.10867 to 9.37593, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 9.37593 to 7.91750, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 7.91750 to 6.69643, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 6.69643 to 5.64761, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 5.64761 to 4.78349, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 4.78349 to 4.12525, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 4.12525 to 3.60338, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 3.60338 to 3.20289, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 3.20289 to 2.86181, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 2.86181 to 2.60367, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 2.60367 to 2.37834, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 2.37834 to 2.20087, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 2.20087 to 2.05372, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 2.05372 to 1.91453, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 1.91453 to 1.80982, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 1.80982 to 1.71703, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 1.71703 to 1.63897, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 1.63897 to 1.57676, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 1.57676 to 1.50900, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 1.50900 to 1.46147, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 1.46147 to 1.41411, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 1.41411 to 1.37521, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 1.37521 to 1.34051, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 1.34051 to 1.30939, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 1.30939 to 1.27872, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 1.27872 to 1.25513, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 1.25513 to 1.23400, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 33: val_loss improved from 1.23400 to 1.21151, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 1.21151 to 1.19521, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 35: val_loss improved from 1.19521 to 1.17997, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 36: val_loss improved from 1.17997 to 1.16568, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 1.16568 to 1.15522, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 38: val_loss improved from 1.15522 to 1.14026, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 39: val_loss improved from 1.14026 to 1.13213, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 40: val_loss improved from 1.13213 to 1.12016, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 41: val_loss improved from 1.12016 to 1.11304, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 42: val_loss improved from 1.11304 to 1.10666, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 43: val_loss improved from 1.10666 to 1.09951, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 44: val_loss improved from 1.09951 to 1.09072, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 45: val_loss improved from 1.09072 to 1.08598, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 46: val_loss improved from 1.08598 to 1.07975, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 47: val_loss improved from 1.07975 to 1.07521, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 48: val_loss improved from 1.07521 to 1.07152, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 49: val_loss improved from 1.07152 to 1.06696, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 50: val_loss improved from 1.06696 to 1.06461, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 51: val_loss improved from 1.06461 to 1.06115, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 52: val_loss improved from 1.06115 to 1.05838, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 53: val_loss improved from 1.05838 to 1.05445, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 54: val_loss improved from 1.05445 to 1.05333, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 55: val_loss improved from 1.05333 to 1.05039, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 56: val_loss improved from 1.05039 to 1.04821, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 57: val_loss improved from 1.04821 to 1.04619, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 58: val_loss improved from 1.04619 to 1.04412, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 59: val_loss improved from 1.04412 to 1.04264, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 60: val_loss improved from 1.04264 to 1.04089, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 61: val_loss improved from 1.04089 to 1.03977, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 62: val_loss improved from 1.03977 to 1.03863, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 63: val_loss improved from 1.03863 to 1.03780, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 64: val_loss improved from 1.03780 to 1.03635, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 65: val_loss improved from 1.03635 to 1.03510, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 66: val_loss improved from 1.03510 to 1.03468, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 67: val_loss improved from 1.03468 to 1.03414, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 68: val_loss improved from 1.03414 to 1.03316, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 69: val_loss improved from 1.03316 to 1.03228, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 70: val_loss improved from 1.03228 to 1.03165, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 71: val_loss improved from 1.03165 to 1.03144, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 72: val_loss improved from 1.03144 to 1.03058, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 73: val_loss improved from 1.03058 to 1.03032, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 74: val_loss improved from 1.03032 to 1.03011, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 75: val_loss improved from 1.03011 to 1.02965, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 76: val_loss improved from 1.02965 to 1.02938, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 77: val_loss improved from 1.02938 to 1.02899, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 78: val_loss improved from 1.02899 to 1.02874, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 79: val_loss improved from 1.02874 to 1.02855, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 80: val_loss improved from 1.02855 to 1.02835, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 81: val_loss improved from 1.02835 to 1.02817, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 82: val_loss improved from 1.02817 to 1.02799, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 83: val_loss improved from 1.02799 to 1.02777, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 84: val_loss improved from 1.02777 to 1.02757, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 85: val_loss improved from 1.02757 to 1.02735, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 86: val_loss improved from 1.02735 to 1.02721, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 87: val_loss improved from 1.02721 to 1.02712, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 88: val_loss improved from 1.02712 to 1.02703, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 89: val_loss improved from 1.02703 to 1.02691, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 90: val_loss improved from 1.02691 to 1.02685, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 91: val_loss improved from 1.02685 to 1.02675, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 92: val_loss improved from 1.02675 to 1.02671, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 93: val_loss improved from 1.02671 to 1.02663, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 94: val_loss improved from 1.02663 to 1.02657, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 95: val_loss improved from 1.02657 to 1.02652, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 96: val_loss improved from 1.02652 to 1.02648, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 97: val_loss improved from 1.02648 to 1.02643, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 98: val_loss improved from 1.02643 to 1.02641, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 99: val_loss improved from 1.02641 to 1.02639, saving model to checkpoint_trial_3.h5\n",
      "\n",
      "Epoch 100: val_loss improved from 1.02639 to 1.02636, saving model to checkpoint_trial_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:14:02,954] Trial 3 finished with value: 1.0263599157333374 and parameters: {'learning_rate': 0.0001646380669446315, 'lstm_units': [50, 50, 50], 'dense_units': [64, 32], 'dropout_rate_lstm': 0.0008292597418317893, 'dropout_rate_dense': 0.19344119975919805, 'dropout_rate_cnn': 0.2221438728568249, 'l2_reg': 0.06892918516561626, 'cnn_filters': [128, 64]}. Best is trial 1 with value: 0.4351724088191986.\n",
      "2024-06-08 01:14:03,157 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 33.09909, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 33.09909 to 24.80254, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 24.80254 to 18.61386, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 18.61386 to 14.02281, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 14.02281 to 10.62572, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 10.62572 to 8.09331, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 8.09331 to 6.21034, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 6.21034 to 4.79690, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 4.79690 to 3.74073, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 3.74073 to 2.94250, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 2.94250 to 2.40637, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 2.40637 to 2.01485, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 2.01485 to 1.72742, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 1.72742 to 1.51164, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 1.51164 to 1.34158, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 1.34158 to 1.21575, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 1.21575 to 1.11378, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 1.11378 to 1.03048, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 1.03048 to 0.95816, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.95816 to 0.91182, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.91182 to 0.86910, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.86910 to 0.82594, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.82594 to 0.79185, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.79185 to 0.76549, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.76549 to 0.74029, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.74029 to 0.71991, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.71991 to 0.70407, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.70407 to 0.69017, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.69017 to 0.67702, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.67702 to 0.66738, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.66738 to 0.65456, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.65456 to 0.64461, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.64461 to 0.64009, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.64009 to 0.63086, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.63086 to 0.62589, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.62589 to 0.61868, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.61868 to 0.61465, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.61465 to 0.61091, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.61091 to 0.60488, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.60488 to 0.60330, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.60330 to 0.59807, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 42: val_loss improved from 0.59807 to 0.59566, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 43: val_loss improved from 0.59566 to 0.59395, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 44: val_loss improved from 0.59395 to 0.59037, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.59037 to 0.58821, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 46: val_loss improved from 0.58821 to 0.58633, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.58633 to 0.58435, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 48: val_loss improved from 0.58435 to 0.58352, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 49: val_loss improved from 0.58352 to 0.58198, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 50: val_loss improved from 0.58198 to 0.58058, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 51: val_loss improved from 0.58058 to 0.57933, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 52: val_loss improved from 0.57933 to 0.57782, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 53: val_loss improved from 0.57782 to 0.57688, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 54: val_loss improved from 0.57688 to 0.57591, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 55: val_loss improved from 0.57591 to 0.57497, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 56: val_loss improved from 0.57497 to 0.57418, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 57: val_loss improved from 0.57418 to 0.57332, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 58: val_loss improved from 0.57332 to 0.57282, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 59: val_loss improved from 0.57282 to 0.57225, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 60: val_loss improved from 0.57225 to 0.57212, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 61: val_loss improved from 0.57212 to 0.57131, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 62: val_loss improved from 0.57131 to 0.57066, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 63: val_loss improved from 0.57066 to 0.57015, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 64: val_loss improved from 0.57015 to 0.56990, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 65: val_loss improved from 0.56990 to 0.56944, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 66: val_loss improved from 0.56944 to 0.56916, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 67: val_loss improved from 0.56916 to 0.56888, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 68: val_loss improved from 0.56888 to 0.56834, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 69: val_loss improved from 0.56834 to 0.56810, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 70: val_loss improved from 0.56810 to 0.56772, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 71: val_loss improved from 0.56772 to 0.56752, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 72: val_loss improved from 0.56752 to 0.56728, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 73: val_loss improved from 0.56728 to 0.56709, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 74: val_loss improved from 0.56709 to 0.56697, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 75: val_loss improved from 0.56697 to 0.56683, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 76: val_loss improved from 0.56683 to 0.56672, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 77: val_loss improved from 0.56672 to 0.56657, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 78: val_loss improved from 0.56657 to 0.56648, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 79: val_loss improved from 0.56648 to 0.56640, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 80: val_loss improved from 0.56640 to 0.56632, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 81: val_loss improved from 0.56632 to 0.56625, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 82: val_loss improved from 0.56625 to 0.56616, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 83: val_loss improved from 0.56616 to 0.56606, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 84: val_loss improved from 0.56606 to 0.56596, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 85: val_loss improved from 0.56596 to 0.56587, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 86: val_loss improved from 0.56587 to 0.56581, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 87: val_loss improved from 0.56581 to 0.56576, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.56576\n",
      "\n",
      "Epoch 89: val_loss improved from 0.56576 to 0.56571, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 90: val_loss improved from 0.56571 to 0.56566, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 91: val_loss improved from 0.56566 to 0.56563, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 92: val_loss improved from 0.56563 to 0.56559, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 93: val_loss improved from 0.56559 to 0.56557, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 94: val_loss improved from 0.56557 to 0.56554, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 95: val_loss improved from 0.56554 to 0.56552, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 96: val_loss improved from 0.56552 to 0.56549, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 97: val_loss improved from 0.56549 to 0.56548, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 98: val_loss improved from 0.56548 to 0.56545, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 99: val_loss improved from 0.56545 to 0.56545, saving model to checkpoint_trial_4.h5\n",
      "\n",
      "Epoch 100: val_loss improved from 0.56545 to 0.56544, saving model to checkpoint_trial_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:16:30,133] Trial 4 finished with value: 0.5654416084289551 and parameters: {'learning_rate': 0.00021650256475468853, 'lstm_units': [128], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.4937000685827048, 'dropout_rate_dense': 0.2537556218165417, 'dropout_rate_cnn': 0.39972182305994397, 'l2_reg': 0.09452386576527523, 'cnn_filters': [64, 128]}. Best is trial 1 with value: 0.4351724088191986.\n",
      "2024-06-08 01:16:30,423 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.56848, saving model to checkpoint_trial_5.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.56848 to 0.43680, saving model to checkpoint_trial_5.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.43680 to 0.38221, saving model to checkpoint_trial_5.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.38221\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.38221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:17:14,692] Trial 5 finished with value: 0.382205069065094 and parameters: {'learning_rate': 0.003037300395728949, 'lstm_units': [50, 50, 50], 'dense_units': [128, 64], 'dropout_rate_lstm': 0.37893809762747804, 'dropout_rate_dense': 0.16698190579381128, 'dropout_rate_cnn': 0.37115202638566963, 'l2_reg': 0.0286245683690881, 'cnn_filters': [64, 32]}. Best is trial 5 with value: 0.382205069065094.\n",
      "2024-06-08 01:17:14,929 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 11.24148, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 11.24148 to 6.96048, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 6.96048 to 4.36391, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 4.36391 to 2.79653, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 2.79653 to 1.83305, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 1.83305 to 1.26366, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 1.26366 to 0.92193, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.92193 to 0.70301, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.70301 to 0.59948, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.59948 to 0.52864, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.52864 to 0.48127, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.48127 to 0.43405, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.43405\n",
      "\n",
      "Epoch 14: val_loss improved from 0.43405 to 0.43382, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.43382 to 0.42174, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.42174 to 0.41962, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.41962 to 0.40253, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.40253\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.40253\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.40253\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.40253\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.40253\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.40253\n",
      "\n",
      "Epoch 24: val_loss improved from 0.40253 to 0.40142, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.40142 to 0.40087, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.40087 to 0.39913, saving model to checkpoint_trial_6.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.39913\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.39913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:18:37,743] Trial 6 finished with value: 0.39913150668144226 and parameters: {'learning_rate': 0.00045561373051610426, 'lstm_units': [64, 64], 'dense_units': [64, 64], 'dropout_rate_lstm': 0.12597398467315885, 'dropout_rate_dense': 0.07798416271407249, 'dropout_rate_cnn': 0.2759042954698248, 'l2_reg': 0.06013075821099163, 'cnn_filters': [64, 32]}. Best is trial 5 with value: 0.382205069065094.\n",
      "2024-06-08 01:18:37,970 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.07887, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 4.07887 to 2.30603, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 2.30603 to 1.40556, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 1.40556 to 0.91361, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.91361 to 0.65960, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.65960 to 0.52280, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.52280 to 0.45669, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.45669 to 0.41690, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.41690 to 0.40661, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.40661\n",
      "\n",
      "Epoch 11: val_loss improved from 0.40661 to 0.39877, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.39877 to 0.38623, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.38623 to 0.38417, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.38417 to 0.37179, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.37179\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.37179\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.37179\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.37179\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.37179\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.37179\n",
      "\n",
      "Epoch 21: val_loss improved from 0.37179 to 0.37167, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.37167\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.37167\n",
      "\n",
      "Epoch 24: val_loss improved from 0.37167 to 0.37039, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.37039 to 0.36949, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.36949\n",
      "\n",
      "Epoch 27: val_loss improved from 0.36949 to 0.36678, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.36678\n",
      "\n",
      "Epoch 29: val_loss improved from 0.36678 to 0.36629, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.36629\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.36629\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.36629\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.36629\n",
      "\n",
      "Epoch 34: val_loss improved from 0.36629 to 0.36461, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.36461\n",
      "\n",
      "Epoch 36: val_loss improved from 0.36461 to 0.36455, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.36455 to 0.36365, saving model to checkpoint_trial_7.h5\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.36365\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.36365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:20:22,869] Trial 7 finished with value: 0.36364850401878357 and parameters: {'learning_rate': 0.0006673334187485073, 'lstm_units': [32, 32], 'dense_units': [64, 64], 'dropout_rate_lstm': 0.3162358680022379, 'dropout_rate_dense': 0.4056970729608101, 'dropout_rate_cnn': 0.33179159213069287, 'l2_reg': 0.025505817212140094, 'cnn_filters': [32, 64]}. Best is trial 7 with value: 0.36364850401878357.\n",
      "2024-06-08 01:20:23,104 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.88070, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.88070 to 0.60436, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.60436 to 0.53400, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.53400 to 0.51937, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.51937\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.51937\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.51937\n",
      "\n",
      "Epoch 8: val_loss improved from 0.51937 to 0.49143, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.49143\n",
      "\n",
      "Epoch 17: val_loss improved from 0.49143 to 0.49053, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.49053\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.49053\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.49053\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.49053\n",
      "\n",
      "Epoch 22: val_loss improved from 0.49053 to 0.47373, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.47373\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.47373\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.47373\n",
      "\n",
      "Epoch 26: val_loss improved from 0.47373 to 0.47262, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.47262\n",
      "\n",
      "Epoch 28: val_loss improved from 0.47262 to 0.47193, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.47193\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.47193\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.47193\n",
      "\n",
      "Epoch 32: val_loss improved from 0.47193 to 0.46849, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.46849\n",
      "\n",
      "Epoch 34: val_loss improved from 0.46849 to 0.46829, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.46829\n",
      "\n",
      "Epoch 36: val_loss improved from 0.46829 to 0.46716, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.46716\n",
      "\n",
      "Epoch 38: val_loss improved from 0.46716 to 0.46081, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.46081\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.46081\n",
      "\n",
      "Epoch 41: val_loss improved from 0.46081 to 0.45953, saving model to checkpoint_trial_8.h5\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.45953\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.45953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:22:21,844] Trial 8 finished with value: 0.45953068137168884 and parameters: {'learning_rate': 0.007978032341835832, 'lstm_units': [32, 32], 'dense_units': [64, 32, 16], 'dropout_rate_lstm': 0.3698842488555696, 'dropout_rate_dense': 0.48182526621486454, 'dropout_rate_cnn': 0.111756327087434, 'l2_reg': 0.08834862116652137, 'cnn_filters': [32, 64]}. Best is trial 7 with value: 0.36364850401878357.\n",
      "2024-06-08 01:22:22,083 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 5.78135, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 5.78135 to 2.93768, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 2.93768 to 1.58398, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 1.58398 to 0.97227, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.97227 to 0.68553, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.68553 to 0.56050, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.56050 to 0.48059, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.48059 to 0.45242, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.45242\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.45242\n",
      "\n",
      "Epoch 11: val_loss improved from 0.45242 to 0.42549, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.42549\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.42549\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.42549\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.42549\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.42549\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.42549\n",
      "\n",
      "Epoch 18: val_loss improved from 0.42549 to 0.41949, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.41949\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.41949\n",
      "\n",
      "Epoch 21: val_loss improved from 0.41949 to 0.41422, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.41422\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.41422\n",
      "\n",
      "Epoch 24: val_loss improved from 0.41422 to 0.41413, saving model to checkpoint_trial_9.h5\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.41413\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.41413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:23:42,235] Trial 9 finished with value: 0.41412994265556335 and parameters: {'learning_rate': 0.0007646401039674116, 'lstm_units': [32, 32], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.2555803001970955, 'dropout_rate_dense': 0.28904404142469536, 'dropout_rate_cnn': 0.2597992060150098, 'l2_reg': 0.03674509792923869, 'cnn_filters': [64, 32]}. Best is trial 7 with value: 0.36364850401878357.\n",
      "2024-06-08 01:23:42,481 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50456, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.50456 to 0.40897, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.40897 to 0.39243, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.39243 to 0.37217, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.37217 to 0.34130, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.34130 to 0.33835, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.33835 to 0.32974, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.32974\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.32974\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.32974\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.32974\n",
      "\n",
      "Epoch 12: val_loss improved from 0.32974 to 0.32639, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.32639\n",
      "\n",
      "Epoch 14: val_loss improved from 0.32639 to 0.32547, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.32547\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.32547\n",
      "\n",
      "Epoch 17: val_loss improved from 0.32547 to 0.31841, saving model to checkpoint_trial_10.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.31841\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.31841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:24:46,246] Trial 10 finished with value: 0.3184099793434143 and parameters: {'learning_rate': 0.001942226147937392, 'lstm_units': [128, 128], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.24653190220023607, 'dropout_rate_dense': 0.359837144248401, 'dropout_rate_cnn': 0.4928678377838963, 'l2_reg': 0.001327197877806486, 'cnn_filters': [32, 64]}. Best is trial 10 with value: 0.3184099793434143.\n",
      "2024-06-08 01:24:46,493 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55740, saving model to checkpoint_trial_11.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.55740 to 0.45052, saving model to checkpoint_trial_11.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.45052 to 0.39908, saving model to checkpoint_trial_11.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.39908 to 0.37760, saving model to checkpoint_trial_11.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.37760\n",
      "\n",
      "Epoch 6: val_loss improved from 0.37760 to 0.35604, saving model to checkpoint_trial_11.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.35604 to 0.33533, saving model to checkpoint_trial_11.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.33533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:25:27,636] Trial 11 finished with value: 0.33532825112342834 and parameters: {'learning_rate': 0.0018138110889450994, 'lstm_units': [128, 128], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.21600943824178268, 'dropout_rate_dense': 0.35164123524686347, 'dropout_rate_cnn': 0.4775451942283774, 'l2_reg': 0.0018438732656785028, 'cnn_filters': [32, 64]}. Best is trial 10 with value: 0.3184099793434143.\n",
      "2024-06-08 01:25:27,714 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.42732, saving model to checkpoint_trial_12.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.42732 to 0.40985, saving model to checkpoint_trial_12.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.40985 to 0.38257, saving model to checkpoint_trial_12.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.38257\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.38257\n",
      "\n",
      "Epoch 6: val_loss improved from 0.38257 to 0.32816, saving model to checkpoint_trial_12.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.32816\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.32816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:27:26,242] Trial 12 finished with value: 0.32816022634506226 and parameters: {'learning_rate': 0.0022116804588517727, 'lstm_units': [128, 128], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.17591915390382248, 'dropout_rate_dense': 0.3275082586223575, 'dropout_rate_cnn': 0.4978026432401837, 'l2_reg': 0.0010683377298112014, 'cnn_filters': []}. Best is trial 10 with value: 0.3184099793434143.\n",
      "2024-06-08 01:27:26,318 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.51304, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.51304 to 0.47549, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.47549 to 0.37736, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.37736 to 0.37028, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.37028 to 0.35033, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.35033\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.35033\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.35033\n",
      "\n",
      "Epoch 9: val_loss improved from 0.35033 to 0.34401, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.34401\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.34401\n",
      "\n",
      "Epoch 12: val_loss improved from 0.34401 to 0.32470, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.32470 to 0.31769, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.31769\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.31769\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.31769\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.31769\n",
      "\n",
      "Epoch 18: val_loss improved from 0.31769 to 0.31456, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.31456 to 0.31379, saving model to checkpoint_trial_13.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.31379\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.31379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:31:00,849] Trial 13 finished with value: 0.3137885332107544 and parameters: {'learning_rate': 0.0020480173864953505, 'lstm_units': [128, 128], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.18470476537286523, 'dropout_rate_dense': 0.3266718423697933, 'dropout_rate_cnn': 0.49780292127465126, 'l2_reg': 0.0034287951756400634, 'cnn_filters': []}. Best is trial 13 with value: 0.3137885332107544.\n",
      "2024-06-08 01:31:00,936 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46654, saving model to checkpoint_trial_14.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.46654 to 0.39159, saving model to checkpoint_trial_14.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.39159\n",
      "\n",
      "Epoch 4: val_loss improved from 0.39159 to 0.34720, saving model to checkpoint_trial_14.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.34720\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.34720\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.34720\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.34720\n",
      "\n",
      "Epoch 9: val_loss improved from 0.34720 to 0.33204, saving model to checkpoint_trial_14.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.33204\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.33204\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.33204\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.33204\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.33204\n",
      "\n",
      "Epoch 15: val_loss improved from 0.33204 to 0.32686, saving model to checkpoint_trial_14.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.32686\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.32686\n",
      "\n",
      "Epoch 18: val_loss improved from 0.32686 to 0.31325, saving model to checkpoint_trial_14.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.31325\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.31325\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.31325\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.31325\n",
      "\n",
      "Epoch 23: val_loss improved from 0.31325 to 0.31092, saving model to checkpoint_trial_14.h5\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.31092\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.31092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:35:03,142] Trial 14 finished with value: 0.31091904640197754 and parameters: {'learning_rate': 0.0038930679843661655, 'lstm_units': [128, 128], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.13129485703957935, 'dropout_rate_dense': 0.3612071285548836, 'dropout_rate_cnn': 0.4517666750560064, 'l2_reg': 0.013580472445565739, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:35:03,225 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.53079, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.53079 to 0.39850, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.39850\n",
      "\n",
      "Epoch 4: val_loss improved from 0.39850 to 0.39430, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.39430 to 0.35581, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.35581 to 0.34763, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.34763\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.34763\n",
      "\n",
      "Epoch 9: val_loss improved from 0.34763 to 0.34351, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.34351\n",
      "\n",
      "Epoch 19: val_loss improved from 0.34351 to 0.33533, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.33533\n",
      "\n",
      "Epoch 25: val_loss improved from 0.33533 to 0.32984, saving model to checkpoint_trial_15.h5\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.32984\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.32984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:41:15,516] Trial 15 finished with value: 0.3298356831073761 and parameters: {'learning_rate': 0.003941951468904911, 'lstm_units': [64, 32, 16], 'dense_units': [32, 32], 'dropout_rate_lstm': 0.1331721190116457, 'dropout_rate_dense': 0.10593300624523033, 'dropout_rate_cnn': 0.4266755055596228, 'l2_reg': 0.016615190576337896, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:41:15,594 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.59703, saving model to checkpoint_trial_16.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.59703 to 0.46884, saving model to checkpoint_trial_16.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.46884 to 0.43323, saving model to checkpoint_trial_16.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.43323\n",
      "\n",
      "Epoch 5: val_loss improved from 0.43323 to 0.38186, saving model to checkpoint_trial_16.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.38186\n",
      "\n",
      "Epoch 7: val_loss improved from 0.38186 to 0.37500, saving model to checkpoint_trial_16.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.37500\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.37500\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.37500\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.37500\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.37500\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.37500\n",
      "\n",
      "Epoch 14: val_loss improved from 0.37500 to 0.36175, saving model to checkpoint_trial_16.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.36175\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.36175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:44:01,046] Trial 16 finished with value: 0.3617512583732605 and parameters: {'learning_rate': 0.004823160680691599, 'lstm_units': [64, 32], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.07636671490682179, 'dropout_rate_dense': 0.29028045401711405, 'dropout_rate_cnn': 0.43886716018178573, 'l2_reg': 0.04138876643853079, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:44:01,137 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:44:15,226] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:44:15,303 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:44:24,923] Trial 18 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:44:25,159 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.67034, saving model to checkpoint_trial_19.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.67034 to 0.43482, saving model to checkpoint_trial_19.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.43482 to 0.43090, saving model to checkpoint_trial_19.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.43090\n",
      "\n",
      "Epoch 5: val_loss improved from 0.43090 to 0.42227, saving model to checkpoint_trial_19.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.42227 to 0.39290, saving model to checkpoint_trial_19.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.39290 to 0.35683, saving model to checkpoint_trial_19.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.35683\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.35683\n",
      "\n",
      "Epoch 10: val_loss improved from 0.35683 to 0.35597, saving model to checkpoint_trial_19.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.35597\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.35597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:45:13,304] Trial 19 finished with value: 0.3559695780277252 and parameters: {'learning_rate': 0.005563049105175853, 'lstm_units': [128, 128], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.19815021594689522, 'dropout_rate_dense': 0.26903116152650053, 'dropout_rate_cnn': 0.4475500664993356, 'l2_reg': 0.01151613865083195, 'cnn_filters': [64, 128]}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:45:13,382 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.55742, saving model to checkpoint_trial_20.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.55742 to 0.46757, saving model to checkpoint_trial_20.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.46757\n",
      "\n",
      "Epoch 4: val_loss improved from 0.46757 to 0.35341, saving model to checkpoint_trial_20.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.35341\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.35341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:46:55,114] Trial 20 finished with value: 0.35341015458106995 and parameters: {'learning_rate': 0.0032492781650708003, 'lstm_units': [128, 64], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.28860412751214026, 'dropout_rate_dense': 0.021172422520496337, 'dropout_rate_cnn': 0.3256963369028507, 'l2_reg': 0.028038681201362554, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:46:55,362 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.46608, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.46608 to 0.40224, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.40224 to 0.37249, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.37249 to 0.36165, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.36165\n",
      "\n",
      "Epoch 6: val_loss improved from 0.36165 to 0.35528, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.35528 to 0.35043, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.35043 to 0.34527, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.34527\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.34527\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.34527\n",
      "\n",
      "Epoch 12: val_loss improved from 0.34527 to 0.34112, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.34112 to 0.32303, saving model to checkpoint_trial_21.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.32303\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.32303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:47:48,248] Trial 21 finished with value: 0.32303130626678467 and parameters: {'learning_rate': 0.0017685058569051073, 'lstm_units': [128, 128], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.25713976486409346, 'dropout_rate_dense': 0.34904230081964305, 'dropout_rate_cnn': 0.499101243230265, 'l2_reg': 0.0009545783222711293, 'cnn_filters': [32, 64]}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:47:48,326 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:47:57,844] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:47:58,079 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:48:03,125] Trial 23 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:48:03,199 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.42162, saving model to checkpoint_trial_24.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.42162 to 0.38350, saving model to checkpoint_trial_24.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.38350 to 0.33895, saving model to checkpoint_trial_24.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.33895\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.33895\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.33895\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.33895\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.33895\n",
      "\n",
      "Epoch 9: val_loss improved from 0.33895 to 0.32127, saving model to checkpoint_trial_24.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.32127\n",
      "\n",
      "Epoch 18: val_loss improved from 0.32127 to 0.32069, saving model to checkpoint_trial_24.h5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.32069\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.32069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:53:03,431] Trial 24 finished with value: 0.3206918239593506 and parameters: {'learning_rate': 0.006324190904644606, 'lstm_units': [64, 32, 16], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.10796403061226141, 'dropout_rate_dense': 0.31987163306729394, 'dropout_rate_cnn': 0.45592682790409594, 'l2_reg': 0.006379351608711793, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:53:03,631 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:53:06,497] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:53:06,787 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:53:13,434] Trial 26 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:53:13,511 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:53:27,521] Trial 27 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:53:27,600 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.49080, saving model to checkpoint_trial_28.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.49080 to 0.42920, saving model to checkpoint_trial_28.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.42920\n",
      "\n",
      "Epoch 4: val_loss improved from 0.42920 to 0.40346, saving model to checkpoint_trial_28.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.40346 to 0.40112, saving model to checkpoint_trial_28.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.40112 to 0.36796, saving model to checkpoint_trial_28.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.36796\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.36796\n",
      "\n",
      "Epoch 9: val_loss improved from 0.36796 to 0.34975, saving model to checkpoint_trial_28.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.34975\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.34975\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.34975\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.34975\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.34975\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.34975\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.34975\n",
      "\n",
      "Epoch 17: val_loss improved from 0.34975 to 0.34295, saving model to checkpoint_trial_28.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.34295\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.34295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 01:56:34,113] Trial 28 finished with value: 0.34295088052749634 and parameters: {'learning_rate': 0.004204483029735382, 'lstm_units': [64, 32], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.10040749609875238, 'dropout_rate_dense': 0.22875245700398833, 'dropout_rate_cnn': 0.44942562185108986, 'l2_reg': 0.023506539432773976, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 01:56:34,369 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:56:38,976] Trial 29 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:56:39,266 - LSTM model built and compiled\n",
      "[I 2024-06-08 01:56:46,031] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 01:56:46,106 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.41679, saving model to checkpoint_trial_31.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.41679 to 0.39401, saving model to checkpoint_trial_31.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.39401\n",
      "\n",
      "Epoch 4: val_loss improved from 0.39401 to 0.38043, saving model to checkpoint_trial_31.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.38043 to 0.34053, saving model to checkpoint_trial_31.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.34053\n",
      "\n",
      "Epoch 7: val_loss improved from 0.34053 to 0.32029, saving model to checkpoint_trial_31.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.32029\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.32029\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.32029\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.32029\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.32029\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.32029\n",
      "\n",
      "Epoch 14: val_loss improved from 0.32029 to 0.31471, saving model to checkpoint_trial_31.h5\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.31471\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.31471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:01:03,909] Trial 31 finished with value: 0.3147140145301819 and parameters: {'learning_rate': 0.006681621076102862, 'lstm_units': [64, 32, 16], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.1050868408423489, 'dropout_rate_dense': 0.3207718828954968, 'dropout_rate_cnn': 0.4661426872398262, 'l2_reg': 0.006809877627409737, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 02:01:03,989 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.47386, saving model to checkpoint_trial_32.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.47386 to 0.39427, saving model to checkpoint_trial_32.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.39427\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.39427\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.39427\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.39427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:02:21,398] Trial 32 pruned. Trial was pruned at epoch 6.\n",
      "2024-06-08 02:02:21,478 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.43462, saving model to checkpoint_trial_33.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.43462 to 0.40913, saving model to checkpoint_trial_33.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.40913 to 0.38248, saving model to checkpoint_trial_33.h5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.38248\n",
      "\n",
      "Epoch 5: val_loss improved from 0.38248 to 0.38194, saving model to checkpoint_trial_33.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.38194 to 0.36003, saving model to checkpoint_trial_33.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.36003\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.36003\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.36003\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.36003\n",
      "\n",
      "Epoch 11: val_loss improved from 0.36003 to 0.35227, saving model to checkpoint_trial_33.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.35227 to 0.33525, saving model to checkpoint_trial_33.h5\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.33525\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.33525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:06:16,775] Trial 33 finished with value: 0.3352512717247009 and parameters: {'learning_rate': 0.0036242913562709875, 'lstm_units': [64, 32, 16], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.040621228406365784, 'dropout_rate_dense': 0.45095713821854944, 'dropout_rate_cnn': 0.35704461527276965, 'l2_reg': 0.0005060900659625454, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 02:06:17,041 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:06:21,554] Trial 34 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:06:21,629 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:06:31,647] Trial 35 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:06:31,886 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.42938, saving model to checkpoint_trial_36.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.42938 to 0.38558, saving model to checkpoint_trial_36.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.38558\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.38558\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.38558\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.38558\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.38558\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.38558\n",
      "\n",
      "Epoch 9: val_loss improved from 0.38558 to 0.35415, saving model to checkpoint_trial_36.h5\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.35415\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.35415\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.35415\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.35415\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.35415\n",
      "\n",
      "Epoch 15: val_loss improved from 0.35415 to 0.34664, saving model to checkpoint_trial_36.h5\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.34664\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.34664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:07:33,072] Trial 36 finished with value: 0.34663501381874084 and parameters: {'learning_rate': 0.004763824261019619, 'lstm_units': [128, 64], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.18877342001051273, 'dropout_rate_dense': 0.24631043785823362, 'dropout_rate_cnn': 0.42708841496248595, 'l2_reg': 0.007133843707227142, 'cnn_filters': [64, 128]}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 02:07:33,375 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:07:39,888] Trial 37 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:07:40,180 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:07:46,773] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:07:46,853 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:07:50,465] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:07:50,699 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:07:55,703] Trial 40 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:07:55,779 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.42446, saving model to checkpoint_trial_41.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.42446 to 0.38210, saving model to checkpoint_trial_41.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.38210\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.38210\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.38210\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.38210\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.38210\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.38210\n",
      "\n",
      "Epoch 9: val_loss improved from 0.38210 to 0.35584, saving model to checkpoint_trial_41.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.35584 to 0.33924, saving model to checkpoint_trial_41.h5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.33924\n",
      "\n",
      "Epoch 20: val_loss improved from 0.33924 to 0.32431, saving model to checkpoint_trial_41.h5\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.32431\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.32431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:13:17,476] Trial 41 finished with value: 0.32431456446647644 and parameters: {'learning_rate': 0.006651598524406017, 'lstm_units': [64, 32, 16], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.10634005950963739, 'dropout_rate_dense': 0.31837150372514506, 'dropout_rate_cnn': 0.4559849564215484, 'l2_reg': 0.006083210107288446, 'cnn_filters': []}. Best is trial 14 with value: 0.31091904640197754.\n",
      "2024-06-08 02:13:17,560 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.48756, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.48756 to 0.35510, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.35510\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.35510\n",
      "\n",
      "Epoch 5: val_loss improved from 0.35510 to 0.34812, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.34812\n",
      "\n",
      "Epoch 7: val_loss improved from 0.34812 to 0.31706, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.31706\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.31706\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.31706\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.31706\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.31706\n",
      "\n",
      "Epoch 13: val_loss improved from 0.31706 to 0.31443, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.31443\n",
      "\n",
      "Epoch 15: val_loss improved from 0.31443 to 0.31360, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.31360 to 0.30196, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.30196 to 0.30170, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.30170\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.30170\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.30170\n",
      "\n",
      "Epoch 21: val_loss improved from 0.30170 to 0.29762, saving model to checkpoint_trial_42.h5\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.29762\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.29762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:18:50,101] Trial 42 finished with value: 0.29762405157089233 and parameters: {'learning_rate': 0.006014736743453021, 'lstm_units': [64, 32, 16], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.12668212445133997, 'dropout_rate_dense': 0.35869534862394686, 'dropout_rate_cnn': 0.47870322262507353, 'l2_reg': 0.01043485496493897, 'cnn_filters': []}. Best is trial 42 with value: 0.29762405157089233.\n",
      "2024-06-08 02:18:50,184 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50349, saving model to checkpoint_trial_43.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.50349 to 0.37834, saving model to checkpoint_trial_43.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.37834\n",
      "\n",
      "Epoch 4: val_loss improved from 0.37834 to 0.34336, saving model to checkpoint_trial_43.h5\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.34336\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.34336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:21:21,576] Trial 43 finished with value: 0.34336379170417786 and parameters: {'learning_rate': 0.004787952037404138, 'lstm_units': [64, 32, 16], 'dense_units': [32, 16], 'dropout_rate_lstm': 0.13900557238533529, 'dropout_rate_dense': 0.3576998905802091, 'dropout_rate_cnn': 0.483787456918678, 'l2_reg': 0.012067154609379648, 'cnn_filters': []}. Best is trial 42 with value: 0.29762405157089233.\n",
      "2024-06-08 02:21:21,846 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.49968, saving model to checkpoint_trial_44.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:21:28,982] Trial 44 pruned. Trial was pruned at epoch 1.\n",
      "2024-06-08 02:21:29,070 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:21:43,471] Trial 45 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:21:43,549 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.50320, saving model to checkpoint_trial_46.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:22:08,434] Trial 46 pruned. Trial was pruned at epoch 1.\n",
      "2024-06-08 02:22:08,668 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.44703, saving model to checkpoint_trial_47.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:22:15,543] Trial 47 pruned. Trial was pruned at epoch 1.\n",
      "2024-06-08 02:22:15,620 - LSTM model built and compiled\n",
      "[I 2024-06-08 02:22:25,340] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "2024-06-08 02:22:25,579 - LSTM model built and compiled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.38286, saving model to checkpoint_trial_49.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.38286 to 0.37785, saving model to checkpoint_trial_49.h5\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.37785\n",
      "\n",
      "Epoch 4: val_loss improved from 0.37785 to 0.36667, saving model to checkpoint_trial_49.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.36667 to 0.35334, saving model to checkpoint_trial_49.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.35334 to 0.34825, saving model to checkpoint_trial_49.h5\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.34825\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.34825\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.34825\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.34825\n",
      "\n",
      "Epoch 11: val_loss improved from 0.34825 to 0.34215, saving model to checkpoint_trial_49.h5\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.34215\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.34215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 02:23:16,331] Trial 49 finished with value: 0.3421517312526703 and parameters: {'learning_rate': 0.005217557501351504, 'lstm_units': [128, 128], 'dense_units': [128, 64, 32], 'dropout_rate_lstm': 0.12934319608284747, 'dropout_rate_dense': 0.4159856414903692, 'dropout_rate_cnn': 0.23127158049843335, 'l2_reg': 9.676652152509728e-05, 'cnn_filters': [64, 128]}. Best is trial 42 with value: 0.29762405157089233.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna_integration import TFKerasPruningCallback\n",
    "import gc\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# FunciÃ³n de construcciÃ³n del modelo\n",
    "def build_model(\n",
    "        learning_rate=0.001,\n",
    "        cnn_filters=(),\n",
    "        dense_units=(),\n",
    "        lstm_units=(),\n",
    "        sequence_length=60,\n",
    "        dropout_rate_dense=0, \n",
    "        dropout_rate_lstm=0,\n",
    "        dropout_rate_cnn=0,\n",
    "        add_batch_norm=False,\n",
    "        l2_reg=0.01,\n",
    "):\n",
    "    model = Sequential()\n",
    "\n",
    "    # CNN LAYERS\n",
    "    if cnn_filters:\n",
    "        for i, num_filters in enumerate(cnn_filters):\n",
    "            if i == 0:\n",
    "                model.add(tf.keras.layers.Conv1D(filters=num_filters, kernel_size=3, activation='relu', input_shape=(sequence_length, len(FEATURES))))\n",
    "            else:\n",
    "                model.add(tf.keras.layers.Conv1D(filters=num_filters, kernel_size=3, activation='relu'))\n",
    "            model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "            model.add(Dropout(dropout_rate_cnn))\n",
    "        if add_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "    # LSTM LAYERS\n",
    "    for i, num_units in enumerate(lstm_units):\n",
    "        return_seq = True if i < len(lstm_units) - 1 else False\n",
    "        model.add(RNN(LSTMCell(num_units, activation='tanh', kernel_regularizer=l2(l2_reg)), return_sequences=return_seq))\n",
    "        if add_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_rate_lstm))\n",
    "\n",
    "    # DENSE LAYERS\n",
    "    if dense_units:\n",
    "        for i, num_units in enumerate(dense_units):\n",
    "            model.add(Dense(num_units, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "            if add_batch_norm:\n",
    "                model.add(BatchNormalization())\n",
    "            model.add(Dropout(dropout_rate_dense))\n",
    "\n",
    "    model.add(Dense(len(TARGET_FEATURES)))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "    \n",
    "    logger.info(\"LSTM model built and compiled\")\n",
    "    return model\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return lr * tf.math.exp(-0.1) if epoch >= 10 else lr\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    lstm_units = trial.suggest_categorical('lstm_units', \n",
    "                                           ((128,), (128, 128), (128, 64), (64, 32), (64, 64), (32, 32),\n",
    "                                            (50, 50, 50), (100, 100, 100), (128, 64, 32), (64, 32, 16)))\n",
    "    dense_units = trial.suggest_categorical('dense_units', \n",
    "                                            ((32, 16), (64, 32), (128, 64), (64, 64), (32, 32),\n",
    "                                             (128, 64, 32), (64, 32, 16), (128, 64, 32)))\n",
    "    dropout_rate_lstm = trial.suggest_float('dropout_rate_lstm', 0.0, 0.5)\n",
    "    dropout_rate_dense = trial.suggest_float('dropout_rate_dense', 0.0, 0.5)\n",
    "    dropout_rate_cnn = trial.suggest_float('dropout_rate_cnn', 0.0, 0.5)\n",
    "    l2_reg = trial.suggest_float('l2_reg', 0.0, 0.1)\n",
    "    cnn_filters = trial.suggest_categorical('cnn_filters', ((), (32, 64), (64, 128), (128, 64), (64, 32)))\n",
    "\n",
    "    model = build_model(\n",
    "        learning_rate=learning_rate,\n",
    "        cnn_filters=cnn_filters,\n",
    "        lstm_units=lstm_units,\n",
    "        dense_units=dense_units,\n",
    "        dropout_rate_lstm=dropout_rate_lstm,\n",
    "        dropout_rate_dense=dropout_rate_dense,\n",
    "        dropout_rate_cnn=dropout_rate_cnn,\n",
    "        l2_reg=l2_reg,\n",
    "        sequence_length=SEQ_LENGTH\n",
    "    )\n",
    "    \n",
    "    batch_size = BATCH_SIZE\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=f'checkpoint_trial_{trial.number}.h5', save_weights_only=True, save_best_only=True, monitor='val_loss', verbose=1)\n",
    "    \n",
    "    history = model.fit(train_sequences, train_targets, batch_size=batch_size, epochs=EPOCHS, validation_data=(val_sequences, val_targets), callbacks=[\n",
    "        TFKerasPruningCallback(trial, 'val_loss'),\n",
    "        LearningRateScheduler(scheduler),\n",
    "        EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n",
    "        checkpoint_callback\n",
    "    ], verbose=0)\n",
    "    \n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "def run_dashboard(storage_name):\n",
    "    subprocess.Popen([\"optuna-dashboard\", storage_name])\n",
    "\n",
    "study_name = \"example_study\"  \n",
    "storage_name = \"sqlite:///example_study.db\"  \n",
    "\n",
    "study = optuna.create_study(study_name=study_name, direction='minimize', storage=storage_name, load_if_exists=True)\n",
    "\n",
    "try:\n",
    "    study.optimize(objective, n_trials=50)  \n",
    "except Exception as e:\n",
    "    print(f\"Optimization failed with exception: {e}\")\n",
    "\n",
    "best_trial = study.best_trial\n",
    "results = {\n",
    "    'learning_rate': best_trial.params['learning_rate'],\n",
    "    'cnn_filters': best_trial.params['cnn_filters'],\n",
    "    'lstm_units': best_trial.params['lstm_units'],\n",
    "    'dense_units': best_trial.params['dense_units'],\n",
    "    'dropout_rate_lstm': best_trial.params['dropout_rate_lstm'],\n",
    "    'dropout_rate_dense': best_trial.params['dropout_rate_dense'],\n",
    "    'dropout_rate_cnn': best_trial.params['dropout_rate_cnn'],\n",
    "    'l2_reg': best_trial.params['l2_reg'],\n",
    "    'val_loss': best_trial.value\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv(METRICS_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 02:23:16,376 - LSTM model built and compiled\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_trial_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_trial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_path):\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_sequences, train_targets, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, validation_data\u001b[38;5;241m=\u001b[39m(val_sequences, val_targets), callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, lr_scheduler])\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39msave(MODEL_PATH)\n",
      "File \u001b[1;32mc:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Fco\\miniconda3\\envs\\tfdml_plugin\\lib\\site-packages\\keras\\engine\\training.py:2925\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2920\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2921\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`load_weights` requires h5py package when loading weights \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2922\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom HDF5. Try installing h5py.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2923\u001b[0m     )\n\u001b[0;32m   2924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 2925\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to load weights saved in HDF5 format into a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2927\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclassed Model which has not created its variables yet. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2928\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall the Model first, then load the weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2929\u001b[0m     )\n\u001b[0;32m   2930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_weights_created()\n\u001b[0;32m   2931\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights."
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    learning_rate=best_trial.params['learning_rate'],\n",
    "    cnn_filters=best_trial.params['cnn_filters'],\n",
    "    lstm_units=best_trial.params['lstm_units'],\n",
    "    dense_units=best_trial.params['dense_units'],\n",
    "    dropout_rate_lstm=best_trial.params['dropout_rate_lstm'],\n",
    "    dropout_rate_dense=best_trial.params['dropout_rate_dense'],\n",
    "    dropout_rate_cnn=best_trial.params['dropout_rate_cnn'],\n",
    "    l2_reg=best_trial.params['l2_reg'],\n",
    "    sequence_length=SEQ_LENGTH\n",
    ")\n",
    "\n",
    "checkpoint_path = f'checkpoint_trial_{best_trial.number}.h5'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(train_sequences, train_targets, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(val_sequences, val_targets), callbacks=[early_stopping, lr_scheduler])\n",
    "model.save(MODEL_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdml_plugin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
